{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pymatgen as mg\n",
    "import pymatgen.analysis.diffraction as anadi\n",
    "import pymatgen.analysis.diffraction.xrd as xrd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "torch.set_printoptions(precision=8)\n",
    "\n",
    "patt_xrd = xrd.XRDCalculator('CuKa')\n",
    "\n",
    "train_path='/home/hjj/Desktop/GAN-SMF/train/'\n",
    "\n",
    "test_path='/home/hjj/Desktop/GAN-SMF/test/'\n",
    "\n",
    "global sample_num, rmat_num, series_num\n",
    "sample_num=1 #output of G\n",
    "rmat_num=28  #row nums of the matrix for the input of CNN \n",
    "series_num=3#input of D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy(folder):\n",
    "    energy_string=os.popen('grep TOTEN '+folder+'/OUTCAR | tail -1').read().split(' ')[-2]\n",
    "    energy=round(np.float64(float(energy_string)),5)\n",
    "    return energy\n",
    "\n",
    "def linear_transform(energy):\n",
    "    global extend_num, move_num\n",
    "    energy_transform=(energy-move_num)*extend_num\n",
    "    return energy_transform\n",
    "def inverse_transform(energy_transform):\n",
    "    global extend_num, move_num\n",
    "    energy=energy_transform/extend_num+move_num\n",
    "    return energy\n",
    "def get_energy_per_atom(energy):\n",
    "    energy_per_atom=energy/atoms_num\n",
    "    return energy_per_atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global extend_num, move_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_num=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-175.79261\n"
     ]
    }
   ],
   "source": [
    "move_num=get_energy(train_path+'00000/')\n",
    "print(move_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pxrd_s=mg.Structure.from_file('/home/hjj/Desktop/GAN-SMF/train/00000/CONTCAR')\n",
    "base_pxrd=patt_xrd.get_pattern(base_pxrd_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly select the file path of the input structure\n",
    "def random_xxpsk(file_path):\n",
    "    folder=np.random.choice(glob.glob(file_path +\"*\"))\n",
    "    #pos_name=folder+'/POSCAR'\n",
    "    #out_name=folder+'/OUTCAR'\n",
    "    return folder\n",
    "\n",
    "#transform 'POSCAR' into the formate of pymatgen\n",
    "def tomgStructure(folder):\n",
    "    POSfile=folder+'/CONTCAR'      \n",
    "    R_mgS=mg.Structure.from_file(POSfile)\n",
    "    return R_mgS\n",
    "\n",
    "###\n",
    "##get the pxrd data of a structure via pymatgen, and screen these peaks by intensity and angle\n",
    "### The fourth method\n",
    "\n",
    "def get_xrdmat4(mgStructure):\n",
    "    global rmat_num\n",
    "    xrd_data4 =patt_xrd.get_pattern(mgStructure)\n",
    "    xrd_data4.y=xrd_data4.y-base_pxrd.y\n",
    "    i_column = rmat_num\n",
    "    xxx=[]\n",
    "    yyy=[]\n",
    "    mat4=[]\n",
    "    xrd_i=len(xrd_data4)\n",
    "    for i in range(xrd_i):\n",
    "        if abs(xrd_data4.y[i])>0.00000000001:\n",
    "            xxx.append(xrd_data4.x[i])\n",
    "            yyy.append(xrd_data4.y[i])\n",
    "    mat4.append(np.asarray(xxx))\n",
    "    mat4.append(np.asarray(yyy))\n",
    "    mat4=np.asarray(mat4)\n",
    "    \n",
    "    xrd_x=[]\n",
    "    xrd_y=[]\n",
    "    xrd_mat4=[]\n",
    "    xrow=len(mat4[0])\n",
    "    \n",
    "    if xrow < i_column:\n",
    "        for i in mat4[0]:\n",
    "            xrd_x.append(i)\n",
    "        for j in mat4[1]:\n",
    "            xrd_y.append(j)\n",
    "        for i in range(0,i_column-xrow):\n",
    "            xrd_x.append(0)\n",
    "            xrd_y.append(0)\n",
    "        xrd_x=np.asarray(xrd_x)\n",
    "        xrd_y=np.asarray(xrd_y)\n",
    "    if xrow > i_column:\n",
    "        xrd_x=mat4[0][:i_column]\n",
    "        xrd_y=mat4[1][:i_column]\n",
    "    if xrow == i_column:\n",
    "        xrd_x= mat4[0]\n",
    "        xrd_y= mat4[1]\n",
    "        \n",
    "    \n",
    "    xrd_x=np.sin(np.dot(1/180*np.pi,xrd_x))\n",
    "    xrd_y=np.dot(100,xrd_y)\n",
    "    xrd_mat4.append(xrd_x)\n",
    "    xrd_mat4.append(xrd_y)\n",
    "    xrd_mat4=np.array(xrd_mat4)\n",
    "    return xrd_mat4\n",
    "###\n",
    "##input_data_as_knowlegde\n",
    "###\n",
    "'''\n",
    "def get_Gibbs(folder):\n",
    "    energy_string=os.popen('grep TOTEN '+folder+'/OUTCAR | tail -1').read().split(' ')[-2]\n",
    "    Gibbs=np.float64(float(energy_string))\n",
    "    Gibbs=round(Gibbs,6)\n",
    "    return Gibbs\n",
    "'''\n",
    "##\n",
    "###calculate the number of atoms in a POSCAR via pymatgen\n",
    "\n",
    "def get_atoms_num(folder2):\n",
    "    xxx=tomgStructure(folder2)\n",
    "    anum=len(xxx.sites)\n",
    "    return anum\n",
    "\n",
    "\n",
    "###\n",
    "## generate the graph-structure matrix as the input of GAN\n",
    "###\n",
    "def GANs_Gmat(Random_Structure):\n",
    "    global rmat_num\n",
    "    RS_xrdmat = get_xrdmat4(Random_Structure)\n",
    "    multimat4_RS =  np.zeros((rmat_num,rmat_num),dtype='float32')\n",
    "    multimat4_RS = np.asarray((np.dot(RS_xrdmat.T, RS_xrdmat)))\n",
    "    return multimat4_RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size=(sample_num,28,28)):\n",
    "        super(GNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(#(3,28,28)\n",
    "                in_channels=sample_num,\n",
    "                out_channels=32,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),#->(32,28,28)\n",
    "            nn.ReLU(),#->(32,28,28)\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )#->(#->(32,14,14))\n",
    "        self.conv2=nn.Sequential(#->(32,14,14))\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),#->(64,14,14)\n",
    "            nn.ReLU(),#->(64,14,14)\n",
    "            nn.MaxPool2d(kernel_size=2),#->(64,7,7)\n",
    "        )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Linear(64*7*7,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,sample_num),            \n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x) #batch(64,7,7)\n",
    "        x=x.view(x.size(0),-1) #(batch, 64*7*7)\n",
    "        output=torch.unsqueeze(self.out(x),dim=0)\n",
    "        return output\n",
    "\n",
    "class DNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNet, self).__init__()\n",
    "        self.Dlstm=nn.LSTM(\n",
    "            input_size=series_num,\n",
    "            hidden_size=32,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Linear(32,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10,1),\n",
    "            \n",
    "        )\n",
    "        #nn.Linear(32,1)\n",
    "        #nn.Relu\n",
    "        #nn.Linear\n",
    "        #nn.Sigmoid\n",
    "        \n",
    "    def forward(self,x):\n",
    "        D_out,(h_n,h_c)=self.Dlstm(x,None)\n",
    "        out = self.out(D_out[:,-1,:]) #(batch,time step,input)   \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_Gl=[]    \n",
    "mat_Dl=[]\n",
    "pre_d_real=[]\n",
    "pre_d_fake=[]\n",
    "error_test=[]\n",
    "error_train=[]\n",
    "r2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1=GNet()\n",
    "D1=DNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_D1=torch.optim.Adam(D1.parameters(),lr=0.1)\n",
    "opt_G1=torch.optim.Adam(G1.parameters(),lr=0.052)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization of the series used as the input of D\n",
    "train_series=[]\n",
    "for i in range(series_num):\n",
    "    path_s=random_xxpsk(train_path)\n",
    "    ee1=get_energy(path_s)\n",
    "    ee1=linear_transform(ee1)\n",
    "    train_series.append(ee1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=train_path\n",
    "used_file_set=[]\n",
    "for step in range(1,4):       \n",
    " \n",
    "    #modules: control the POSCARs used for training\n",
    "    sample_path=[]\n",
    "    for i in range(1,sample_num + 1):\n",
    "        path_ = random_xxpsk(file_path)\n",
    "        sample_path.append(path_)\n",
    "        used_file_set.append(path_)\n",
    "   \n",
    "    # update the train-series when x=real\n",
    "    E_Gibbs=0\n",
    "    for path1_ in sample_path:\n",
    "        try:\n",
    "            total_energy=get_energy(path1_)\n",
    "            E_Gibbs=linear_transform(total_energy)\n",
    "            \n",
    "        except:\n",
    "            print(path1_)\n",
    "         \n",
    "        train_series.pop(-1)\n",
    "        train_series.append(E_Gibbs)\n",
    "        \n",
    "        \n",
    "    input_series_D=np.asarray(train_series,dtype=np.float64)       \n",
    "    input_series_D=Variable(torch.from_numpy(input_series_D[np.newaxis,np.newaxis,:]),requires_grad=True)\n",
    "    \n",
    "    d_real=D1(input_series_D)\n",
    "    pre_d_real.append(d_real.data.numpy().mean())\n",
    "    \n",
    "    # update the train-series when x=fake \n",
    "    g_in=[]\n",
    "    for path2_ in sample_path:\n",
    "        path2_=str(path2_)                \n",
    "        \n",
    "        try:\n",
    "            tomgS=tomgStructure(path2_)            \n",
    "            gin=GANs_Gmat(tomgS)  \n",
    "        except:\n",
    "            pass\n",
    "        g_in.append(gin)\n",
    "       \n",
    "    g_in=np.asarray(g_in)\n",
    "    g_in=g_in[np.newaxis,:,:,:] \n",
    "    g_in=np.asarray(g_in,dtype=np.float64) \n",
    "    g_in=Variable(torch.from_numpy(g_in),requires_grad=True)\n",
    "    \n",
    "    G_fake=G1(g_in)\n",
    "    Gout=round(G_fake.data.numpy().mean(),6)\n",
    "    \n",
    "    train_series.pop(0)\n",
    "    train_series.append(Gout)\n",
    "    \n",
    "        \n",
    "    input_series_D=np.asarray(train_series,dtype=np.float64)       \n",
    "    input_series_D=Variable(torch.from_numpy(input_series_D[np.newaxis,np.newaxis,:]),requires_grad=True)\n",
    "    \n",
    "    \n",
    "    d_fake=D1(input_series_D)\n",
    "    pre_d_fake.append(d_fake.data.numpy().mean())\n",
    "    \n",
    "    D1_loss=-torch.mean(torch.log(d_real)+torch.log(1.- d_fake))   \n",
    "    dd=D1_loss.data.numpy().mean()\n",
    "    mat_Dl.append(dd)\n",
    "    \n",
    "    G1_loss=torch.mean(d_fake)\n",
    "    gg=G1_loss.data.numpy().mean()\n",
    "    mat_Gl.append(gg)\n",
    "    \n",
    "    if step%1==0:\n",
    "        opt_D1.zero_grad()\n",
    "        D1_loss.backward(retain_graph=True)\n",
    "        opt_D1.step()\n",
    "        \n",
    "        opt_G1.zero_grad()\n",
    "        G1_loss.backward()\n",
    "        opt_G1.step()\n",
    "    else:\n",
    "        opt_D1.zero_grad()\n",
    "        D1_loss.backward()\n",
    "        opt_D1.step()\n",
    "    \n",
    "\n",
    "\n",
    "    if step%1==0:\n",
    "        print(step)\n",
    "        print('error: ',abs(inverse_transform(Gout)-inverse_transform(E_Gibbs)))        \n",
    "        print(dd)\n",
    "        print(gg)\n",
    "        print(\"real:\",d_real.data.numpy().mean())\n",
    "        print(\"fake:\",d_fake.data.numpy().mean())\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    if step%1==0:\n",
    "        print('----------------------------------test-------------------------')\n",
    "        file_path_test=test_path\n",
    "        E_Gibbs_1=[]\n",
    "        E_Gmodel_1=[]\n",
    "        for step_test in range(8):\n",
    "            sample_path=[]\n",
    "            for i in range(1,sample_num + 1):\n",
    "                path_ = random_xxpsk(file_path_test)\n",
    "                sample_path.append(path_)\n",
    "            \n",
    "            for path1_ in sample_path:\n",
    "                try:\n",
    "                    total_energy=get_energy(path1_)\n",
    "                    tt_energy=linear_transform(total_energy)\n",
    "            #print(samp_Gibbs)\n",
    "                except:\n",
    "                    print(path1_)\n",
    "                    \n",
    "            tt_energy=inverse_transform(float(tt_energy))\n",
    "            print('DFT',tt_energy)\n",
    "            E_Gibbs_1.append(tt_energy)\n",
    "        \n",
    "                   \n",
    "\n",
    "        #print(tfactor.shape)\n",
    "    \n",
    "            g_in=[]\n",
    "            for path2_ in sample_path:\n",
    "                path2_=str(path2_)                \n",
    "        \n",
    "                try:\n",
    "                    tomgS=tomgStructure(path2_)\n",
    "            #print(tomgS)\n",
    "                    gin=GANs_Gmat(tomgS)\n",
    "                    \n",
    "            #print(gin)\n",
    "                except:\n",
    "                    pass\n",
    "                g_in.append(gin)\n",
    "       \n",
    "            g_in=np.asarray(g_in)\n",
    "            g_in=g_in[np.newaxis,:,:,:] \n",
    "            g_in=np.asarray(g_in,dtype=np.float64) \n",
    "            g_in=Variable(torch.from_numpy(g_in),requires_grad=True)\n",
    "    \n",
    "            Gout=G1(g_in)\n",
    "        \n",
    "        #print(Gout.shape)\n",
    "    \n",
    "            G_data=round(inverse_transform(Gout.data.numpy().mean()),6)\n",
    "            print('G_predict',G_data)\n",
    "            E_Gmodel_1.append(G_data)\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "            print('error',abs(tt_energy-G_data))\n",
    "            \n",
    "        print('------------------end-test----------------------------')\n",
    "        xxx=abs(abs(np.asarray(E_Gibbs_1))-abs(np.asarray(E_Gmodel_1))).mean()\n",
    "        print(xxx)\n",
    "        error_test.append(xxx)\n",
    "        \n",
    "        X=np.asarray(E_Gibbs_1)\n",
    "        Y=np.asarray(E_Gmodel_1)\n",
    "\n",
    "        xbar=X.mean()\n",
    "        ybar=Y.mean()\n",
    "        SSR=0\n",
    "        varX=0\n",
    "        varY=0\n",
    "        for i in range(len(X)):\n",
    "            diffxxbar=X[i]-xbar\n",
    "            diffyybar=Y[i]-ybar\n",
    "            SSR+=(diffxxbar*diffyybar)\n",
    "            varX+=diffxxbar**2\n",
    "            varY+=diffyybar**2\n",
    "    \n",
    "        SST=math.sqrt(varX+varY)\n",
    "        R2=(SSR/SST)**2\n",
    "        print(\"R2:\",R2)\n",
    "        r2.append(R2)\n",
    "    else:\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "E_Gibbs_test=[]\n",
    "E_Gmodel_test=[]\n",
    "abserrset=[]\n",
    "MSEset=[]\n",
    "err0set=[]\n",
    "testfile=[]\n",
    "for m1,n1,fname in os.walk(test_path):\n",
    "    for ieach in n1:\n",
    "        ieach=test_path+ieach\n",
    "        testfile.append(ieach)\n",
    "start=time.time()        \n",
    "for path_ in testfile:\n",
    "    try:\n",
    "        GGG=get_energy(path_)\n",
    "        #GGG=inverse_transform(GGG)\n",
    "        E_Gibbs_test.append(GGG)\n",
    "        \n",
    "        g_in=[]\n",
    "        tomgS=tomgStructure(path_)\n",
    "        gin=GANs_Gmat(tomgS)\n",
    "        g_in.append(gin)\n",
    "        g_in=np.asarray(g_in)\n",
    "        g_in=g_in[np.newaxis,:,:,:]\n",
    "        g_in=np.asarray(g_in,dtype=np.float64)\n",
    "        g_in=Variable(torch.from_numpy(g_in),requires_grad=True)\n",
    "        Gout=G1(g_in)\n",
    "        G_data=Gout.data.numpy().mean()\n",
    "        G_data=inverse_transform(G_data)\n",
    "        #G_data=get_energy_per_atom(G_data)\n",
    "        E_Gmodel_test.append(G_data)\n",
    "        #print(G_data)\n",
    "        #print(GGG)\n",
    "        abserr=abs(G_data-GGG)\n",
    "        mse=(G_data-GGG)**2\n",
    "        abserrset.append(abserr)\n",
    "        MSEset.append(mse)\n",
    "        err0=abs(abserr/GGG)\n",
    "        err0set.append(err0)\n",
    "    except:\n",
    "        print(path_)\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.asarray(abserrset).mean())\n",
    "\n",
    "print(np.asarray(MSEset).mean())\n",
    "\n",
    "print(np.sqrt(np.asarray(MSEset).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_Gibbs_t=[]\n",
    "E_Gmodel_t=[]\n",
    "abs_t_errset=[]\n",
    "err_t_0set=[]\n",
    "tMSEset=[]\n",
    "testfile=[]\n",
    "for m1,n1,fname in os.walk(train_path):\n",
    "    for ieach in n1:\n",
    "        ieach=train_path+ieach\n",
    "        testfile.append(ieach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#'''        \n",
    "for path_ in testfile:\n",
    "    try:\n",
    "        GGG=get_energy(path_)\n",
    "        \n",
    "        #GGG=get_energy_per_atom(GGG)\n",
    "        E_Gibbs_t.append(GGG)\n",
    "        g_in=[]\n",
    "        tomgS=tomgStructure(path_)\n",
    "        gin=GANs_Gmat(tomgS)\n",
    "        g_in.append(gin)\n",
    "        g_in=np.asarray(g_in)\n",
    "        g_in=g_in[np.newaxis,:,:,:]\n",
    "        g_in=np.asarray(g_in,dtype=np.float64)\n",
    "        g_in=Variable(torch.from_numpy(g_in),requires_grad=True)\n",
    "        Gout=G1(g_in)\n",
    "        G_data=Gout.data.numpy().mean()\n",
    "        G_data=inverse_transform(G_data)\n",
    "        #G_data=get_energy_per_atom(G_data)\n",
    "        E_Gmodel_t.append(G_data)\n",
    "        #print(G_data)\n",
    "        #print(GGG)\n",
    "        abserr=abs(G_data-GGG)\n",
    "        tmse=(G_data-GGG)**2\n",
    "        tMSEset.append(tmse)\n",
    "        abs_t_errset.append(abserr)\n",
    "        err0=abs(abserr/GGG)\n",
    "        err_t_0set.append(err0)\n",
    "    except:\n",
    "        print(path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.asarray(abs_t_errset).mean())\n",
    "\n",
    "print(np.asarray(tMSEset).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(np.asarray(tMSEset).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G1.state_dict(),\"G1.pkl\") \n",
    "torch.save(D1.state_dict(),\"D1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sample_path=[]\n",
    "sample_path.append('/home/mii/Desktop/cpx222/train/00000')\n",
    "g_in=[]\n",
    "for path2_ in sample_path:\n",
    "    path2_=str(path2_)                \n",
    "        \n",
    "    try:\n",
    "        tomgS=tomgStructure(path2_)\n",
    "            #print(tomgS)\n",
    "        gin=GANs_Gmat(tomgS)\n",
    "                \n",
    "            #print(gin)\n",
    "    except:\n",
    "        pass\n",
    "    g_in.append(gin)\n",
    "       \n",
    "g_in=np.asarray(g_in)\n",
    "g_in=g_in[np.newaxis,:,:,:] \n",
    "g_in=np.asarray(g_in,dtype=np.float64) \n",
    "g_in=Variable(torch.from_numpy(g_in),requires_grad=True)\n",
    "    \n",
    "Gout=G1(g_in)\n",
    "        \n",
    "        #print(Gout.shape)\n",
    "    \n",
    "G_data=round(inverse_transform(Gout.data.numpy().mean()),6)\n",
    "print('G_predict',G_data)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensroflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
